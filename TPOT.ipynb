{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPOT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvXDiF55xgXs"
      },
      "source": [
        "!pip install tpot\n",
        " \n",
        " \n",
        " \n",
        "from tpot import  TPOTRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.datasets import load_boston\n",
        " \n",
        " \n",
        "import pandas as pd #this is how we usually import pandas\n",
        "import numpy as np #this is how we usually import numpy\n",
        " \n",
        "import matplotlib #only needed to determine Matplotlib version number\n",
        "#import tables # pytables is needed to read and write hdf5 files\n",
        "#import openpyxl # is used to read and write MS Excel files\n",
        "import scipy.stats as stats\n",
        " \n",
        "import xgboost\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOqa9bm7_lbK"
      },
      "source": [
        "use TPOT autoML to find  best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ALxkNmOcAV"
      },
      "source": [
        "**cd** =  k-fold cross validation \n",
        "\n",
        "**n_jobs=-1**\n",
        "use all available cores:\n",
        "\n",
        "**use_dask=True,n_jobs=-1**\n",
        "TPOT will use as many cores as available on the your Dask cluster. If n_jobs is specified, then it will control the chunk size (10*n_jobs if it is less then offspring size) of parallel training.\n",
        "\n",
        " **max_eval_time_mins= mins**\n",
        "how many minuts for single pipline\n",
        "\n",
        "**warm_start=True**\n",
        "can be useful for running TPOT for a short time on a dataset, checking the results, then resuming the TPOT run from where it left off.\n",
        "\n",
        "**memory='auto'**\n",
        " pipelines can cache the results of each transformer after fitting them. This feature is used to avoid repeated computation by transformers within a pipeline\n",
        "  \n",
        " **template='Selector-Transformer-Regressor'**\n",
        "set specific pipline\n",
        "\n",
        "\n",
        "**periodic_checkpoint_folder: path string**\n",
        "If supplied, a folder in which TPOT will periodically save pipelines in pareto front so far while optimizing.\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfst0JSS_anD"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "CV = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "\n",
        "tpot = TPOTRegressor(generations=5, population_size=40, verbosity=3, cv=LeaveOneOut(),  template='SelectPercentile-Transformer-LassoLarsCV', scoring='neg_mean_absolute_error', random_state=42)\n",
        "\n",
        "tpot.fit(X_train, y_train)\n",
        "\n",
        "#predict test features and return age \n",
        "tpot.predict(X_test)\n",
        "\n",
        "#output model \n",
        "tpot.export('tpot_pipeline.py')\n",
        "\n",
        "#print best pipeline \n",
        "tpot.fitted_pipeline_\n",
        "\n",
        "#print all pipelines\n",
        "tpot.evaluated_individuals_\n",
        "\n",
        "#print MAE score for tests \n",
        "print(tpot.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEZWoolf5o9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33cd0b3-c8c3-43b4-c379-9aca31ae6b38"
      },
      "source": [
        "prd= tpot.predict(X_test)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(y_test, prd)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.605039909450111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNtINA4P5hyw"
      },
      "source": [
        "the predictions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnGNMFLgMKQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b264d3-1fca-4a9b-e557-dc2517936870"
      },
      "source": [
        "tpot.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([48.919323, 32.6825  , 29.739735, 34.025326, 42.518463, 29.246143,\n",
              "       51.480736, 46.413074, 26.64674 , 45.367428, 50.51135 , 29.470652],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}